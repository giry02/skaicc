import requests
import re
import os
from bs4 import BeautifulSoup

# =================================================================================
# [ìŠ¤í¬ë¦½íŠ¸ ì„¤ëª…: PPT Page 213 êµ¬í˜„ (ì´ë™ ìœ„ì¹˜ ì„ íƒ)]
# íŒŒì¼ëª…: page213_move_location.html
# ì£¼ìš” ë‚´ìš©:
# 1. í—¤ë”: "ì„œë¹„ìŠ¤ ì•ˆë‚´" (ì¢Œì¸¡ í™ˆ ì•„ì´ì½˜)
# 2. ë³¸ë¬¸: "ì´ë™í•  ìœ„ì¹˜ë¥¼ ì„ íƒí•´ ì£¼ì„¸ìš”."
# 3. ì„ íƒ ì˜µì…˜: "ê°™ì€ ë°© ë‚´ì—ì„œ ì´ë™", "ë‹¤ë¥¸ ë°©ìœ¼ë¡œ ì´ë™" (2ì—´ ê·¸ë¦¬ë“œ)
# 4. ì•ˆë‚´ ì‚¬í•­: ë°°ì„  ê³µì‚¬ ê´€ë ¨ ì£¼ì˜ì‚¬í•­ í…ìŠ¤íŠ¸
# 5. ë²„íŠ¼: "ì‹ ì²­í•˜ê¸°" (visit_schedule_modal.html ë¡œ ì´ë™)
# =================================================================================

BASE_DIR = 'completed'
if not os.path.exists(BASE_DIR):
    os.makedirs(BASE_DIR)

# 1. ì›ë³¸ HTML ê°€ì ¸ì˜¤ê¸°
print("Fetching pop4.html...")
url = 'https://giry02.dothome.co.kr/pop4.html'
try:
    response = requests.get(url)
    response.encoding = response.apparent_encoding
    html_content = response.text
except Exception as e:
    print(f"Error fetching HTML: {e}")
    exit()

# 2. íƒ€ì´í•‘ í…ìŠ¤íŠ¸ ë³€ê²½
try:
    new_text = "ì´ë™í•  ìœ„ì¹˜ë¥¼ ì„ íƒí•´ ì£¼ì„¸ìš”."
    html_content = re.sub(r'const\s+textToType\s*=\s*".*?";', f'const textToType = "{new_text}";', html_content)
except Exception as e:
    print(f"Regex failed: {e}")

soup = BeautifulSoup(html_content, 'html.parser')

# 3. í—¤ë” ìˆ˜ì •
header = soup.find('header')
if header:
    # í™ˆ ì•„ì´ì½˜
    left_btn = header.find('button')
    if left_btn:
        left_btn.clear()
        home_svg = soup.new_tag('svg', **{
            'xmlns': "http://www.w3.org/2000/svg",
            'width': "24",
            'height': "24",
            'viewBox': "0 0 24 24",
            'fill': "none",
            'stroke': "currentColor",
            'stroke-width': "2",
            'stroke-linecap': "round",
            'stroke-linejoin': "round",
            'class': "lucide lucide-home"
        })
        path1 = soup.new_tag('path', d="m3 9 9-7 9 7v11a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2z")
        path2 = soup.new_tag('polyline', points="9 22 9 12 15 12 15 22")
        home_svg.append(path1)
        home_svg.append(path2)
        left_btn.append(home_svg)

    h1 = header.find('h1')
    if h1: h1.string = "ì„œë¹„ìŠ¤ ì•ˆë‚´"

# 4. ë©”ì¸ ì»¨í…ì¸  êµ¬ì„±
main_body = soup.find(id='main-content-body')
target_anchor = soup.find(id='target-anchor')

if main_body and target_anchor:
    print("UI êµ¬ì„± ì¤‘ (Page 213 Location Selection)...")
    
    # íƒ€ì´í‹€
    h2 = target_anchor.find('h2')
    if h2:
        h2.clear()
        span = soup.new_tag('span', **{'class': 'text-black font-bold'})
        span.string = "ì´ë™í•  ìœ„ì¹˜ë¥¼"
        h2.append(span)
        h2.append(soup.new_tag('br'))
        h2.append("ì„ íƒí•´ ì£¼ì„¸ìš”.")

    target_anchor_extracted = target_anchor.extract()
    main_body.clear()
    
    wrapper = soup.new_tag('div', **{'class': 'flex flex-col h-full bg-white px-1'}) 
    wrapper.append(target_anchor_extracted)
    
    # [4-3] ìœ„ì¹˜ ì„ íƒ ì˜ì—­ (ê°€ì´ë“œ ì¤€ìˆ˜ ì½¤íŒ©íŠ¸ ê·¸ë¦¬ë“œ)
    option_grid = soup.new_tag('div', **{'class': 'mt-6 mb-4 grid grid-cols-2 gap-3'})
    
    card_cls = 'location-option relative flex flex-col items-center justify-center p-4 aspect-square rounded-2xl border border-gray-100 bg-gray-50 cursor-pointer transition-all active:scale-95'
    
    # ì˜µì…˜ 1: ê°™ì€ ë°©
    opt1 = soup.new_tag('div', **{'class': card_cls, 'onclick': "selectLocation(this, 'same_room')"})
    icon1 = soup.new_tag('div', **{'class': 'w-10 h-10 rounded-full bg-white flex items-center justify-center text-xl mb-2 shadow-sm'})
    icon1.string = "ğŸ "
    opt1.append(icon1)
    text1 = soup.new_tag('span', **{'class': 'text-[14px] font-bold text-gray-800 text-center leading-tight'})
    text1.string = "ê°™ì€ ë°© ë‚´ì—ì„œ\nì´ë™"
    # replace newline with br for proper rendering
    text1.clear()
    text1.append("ê°™ì€ ë°© ë‚´ì—ì„œ")
    text1.append(soup.new_tag('br'))
    text1.append("ì´ë™")
    opt1.append(text1)
    
    chk1 = soup.new_tag('div', **{'class': 'absolute top-3 right-3 text-[#5031E5] opacity-0 check-mark'})
    svg1 = soup.new_tag('svg', **{'xmlns':"http://www.w3.org/2000/svg", 'width':"18", 'height':"18", 'viewBox':"0 0 24 24", 'fill':"none", 'stroke':"currentColor", 'stroke-width':"3", 'stroke-linecap':"round", 'stroke-linejoin':"round"})
    svg1.append(soup.new_tag('polyline', points="20 6 9 17 4 12"))
    chk1.append(svg1)
    opt1.append(chk1)
    option_grid.append(opt1)

    # ì˜µì…˜ 2: ë‹¤ë¥¸ ë°©
    opt2 = soup.new_tag('div', **{'class': card_cls, 'onclick': "selectLocation(this, 'diff_room')"})
    icon2 = soup.new_tag('div', **{'class': 'w-10 h-10 rounded-full bg-white flex items-center justify-center text-xl mb-2 shadow-sm'})
    icon2.string = "ğŸšª"
    opt2.append(icon2)
    text2 = soup.new_tag('span', **{'class': 'text-[14px] font-bold text-gray-800 text-center leading-tight'})
    text2.clear()
    text2.append("ë‹¤ë¥¸ ë°©ìœ¼ë¡œ")
    text2.append(soup.new_tag('br'))
    text2.append("ì´ë™")
    opt2.append(text2)
    
    chk2 = soup.new_tag('div', **{'class': 'absolute top-3 right-3 text-[#5031E5] opacity-0 check-mark'})
    svg2 = soup.new_tag('svg', **{'xmlns':"http://www.w3.org/2000/svg", 'width':"18", 'height':"18", 'viewBox':"0 0 24 24", 'fill':"none", 'stroke':"currentColor", 'stroke-width':"3", 'stroke-linecap':"round", 'stroke-linejoin':"round"})
    svg2.append(soup.new_tag('polyline', points="20 6 9 17 4 12"))
    chk2.append(svg2)
    opt2.append(chk2)
    option_grid.append(opt2)
    
    wrapper.append(option_grid)

    # [4-4] ì£¼ì˜ ì‚¬í•­ (Page 213 í…ìŠ¤íŠ¸ ë°˜ì˜)
    info_box = soup.new_tag('div', **{'class': 'bg-[#F1F3F5] rounded-xl p-4 mb-4'})
    info_flex = soup.new_tag('div', **{'class': 'flex gap-2'})
    info_icon = soup.new_tag('div', **{'class': 'w-5 h-5 rounded-full bg-[#868E96] text-white flex items-center justify-center text-[11px] flex-shrink-0 font-bold'})
    info_icon.string = "i"
    info_flex.append(info_icon)
    
    info_txt = soup.new_tag('p', **{'class': 'text-[12px] text-[#495057] leading-relaxed'})
    info_txt.string = "ë‹¨, ë°°ì„  ê³µì‚¬ê°€ í•„ìš”í•˜ê±°ë‚˜ ì™¸ë¶€ë¡œ ë…¸ì¶œë˜ì§€ ì•Šê³  ì•ˆë‚´ ì¥ì¹˜ ì„¤ì¹˜ë¥¼ í•˜ëŠ” ë“±ì€ ì¶”ê°€ ë¹„ìš©ì´ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    info_flex.append(info_txt)
    info_box.append(info_flex)
    wrapper.append(info_box)

    # [4-5] í•˜ë‹¨ ë²„íŠ¼
    btn_div = soup.new_tag('div', **{'class': 'mt-auto pt-2 pb-4'})
    sub_btn = soup.new_tag('button', **{
        'id': 'apply-btn', 
        'class': 'w-full bg-[#E9ECEF] text-[#ADB5BD] py-4 rounded-xl text-[18px] font-bold transition-all cursor-not-allowed',
        'disabled': 'disabled',
        'onclick': "goToSchedule()"
    })
    sub_btn.string = "ì‹ ì²­í•˜ê¸°"
    btn_div.append(sub_btn)
    wrapper.append(btn_div)
    
    main_body.append(wrapper)

    # JS
    js_content = """
    <script>
    let selectedLoc = null;

    function selectLocation(el, loc) {
        document.querySelectorAll('.location-option').forEach(opt => {
            opt.classList.remove('border-[#5031E5]', 'bg-[#eff6ff]', 'ring-2', 'ring-[#5031E5]/20');
            opt.classList.add('border-gray-100', 'bg-gray-50');
            opt.querySelector('.check-mark').classList.add('opacity-0');
        });

        el.classList.remove('border-gray-100', 'bg-gray-50');
        el.classList.add('border-[#5031E5]', 'bg-[#eff6ff]', 'ring-2', 'ring-[#5031E5]/20');
        el.querySelector('.check-mark').classList.remove('opacity-0');
        
        selectedLoc = loc;
        
        const btn = document.getElementById('apply-btn');
        btn.disabled = false;
        btn.onclick = () => location.href = 'visit_schedule_modal.html';
        btn.classList.remove('bg-[#E9ECEF]', 'text-[#ADB5BD]', 'cursor-not-allowed');
        btn.classList.add('bg-[#5031E5]', 'text-white', 'shadow-lg');
    }
    </script>
    """
    soup.body.append(BeautifulSoup(js_content, 'html.parser'))
    # soup.body.contents[-1].replace_with(BeautifulSoup(js_content, 'html.parser'))

# 5. ì €ì¥
output_filename = os.path.join(BASE_DIR, 'page213_move_location.html')
with open(output_filename, 'w', encoding='utf-8') as f:
    f.write(str(soup))
print(f"HTML ìƒì„± ì™„ë£Œ: {output_filename}")
